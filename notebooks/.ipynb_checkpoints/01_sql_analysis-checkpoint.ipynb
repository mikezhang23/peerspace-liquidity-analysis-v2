{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd648adb-bc89-4185-a3c8-473be2adddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL Analysis Execution Notebook\n",
    "# This notebook runs the SQL queries and visualizes the results\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Connect to database\n",
    "conn = sqlite3.connect('../data/peerspace_marketplace.db')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MARKETPLACE LIQUIDITY SQL ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# =====================================================\n",
    "# SECTION 1: SUPPLY METRICS\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n1. SUPPLY METRICS\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# 1.1 Active Listings Growth\n",
    "query_supply_growth = \"\"\"\n",
    "WITH monthly_supply AS (\n",
    "    SELECT \n",
    "        metro_area,\n",
    "        DATE(created_date, 'start of month') as month,\n",
    "        COUNT(DISTINCT venue_id) as total_venues,\n",
    "        COUNT(DISTINCT CASE WHEN is_active = 1 THEN venue_id END) as active_venues\n",
    "    FROM listings\n",
    "    GROUP BY metro_area, DATE(created_date, 'start of month')\n",
    "),\n",
    "cumulative_supply AS (\n",
    "    SELECT \n",
    "        metro_area,\n",
    "        month,\n",
    "        SUM(active_venues) OVER (PARTITION BY metro_area ORDER BY month) as cumulative_active_venues\n",
    "    FROM monthly_supply\n",
    ")\n",
    "SELECT \n",
    "    metro_area,\n",
    "    month,\n",
    "    cumulative_active_venues\n",
    "FROM cumulative_supply\n",
    "ORDER BY metro_area, month\n",
    "\"\"\"\n",
    "\n",
    "supply_growth_df = pd.read_sql_query(query_supply_growth, conn)\n",
    "supply_growth_df['month'] = pd.to_datetime(supply_growth_df['month'])\n",
    "\n",
    "# Visualize supply growth\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for metro in supply_growth_df['metro_area'].unique():\n",
    "    metro_data = supply_growth_df[supply_growth_df['metro_area'] == metro]\n",
    "    ax.plot(metro_data['month'], metro_data['cumulative_active_venues'], \n",
    "            marker='o', label=metro, linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Cumulative Active Venues')\n",
    "ax.set_title('Supply Growth by Metro Area')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 1.2 Utilization Analysis\n",
    "query_utilization = \"\"\"\n",
    "WITH venue_bookings AS (\n",
    "    SELECT \n",
    "        l.venue_id,\n",
    "        l.metro_area,\n",
    "        l.venue_type,\n",
    "        COUNT(DISTINCT b.booking_id) as total_bookings,\n",
    "        SUM(b.hours_booked) as total_hours_booked\n",
    "    FROM listings l\n",
    "    LEFT JOIN bookings b \n",
    "        ON l.venue_id = b.venue_id \n",
    "        AND b.status = 'completed'\n",
    "    GROUP BY l.venue_id, l.metro_area, l.venue_type\n",
    "),\n",
    "utilization_stats AS (\n",
    "    SELECT \n",
    "        venue_id,\n",
    "        metro_area,\n",
    "        venue_type,\n",
    "        total_bookings,\n",
    "        ROUND(total_hours_booked * 100.0 / (10 * 365), 2) as utilization_rate\n",
    "    FROM venue_bookings\n",
    ")\n",
    "SELECT \n",
    "    metro_area,\n",
    "    venue_type,\n",
    "    COUNT(*) as venue_count,\n",
    "    ROUND(AVG(utilization_rate), 2) as avg_utilization_rate\n",
    "FROM utilization_stats\n",
    "GROUP BY metro_area, venue_type\n",
    "ORDER BY metro_area, avg_utilization_rate DESC\n",
    "\"\"\"\n",
    "\n",
    "utilization_df = pd.read_sql_query(query_utilization, conn)\n",
    "\n",
    "# Create heatmap of utilization\n",
    "pivot_util = utilization_df.pivot(index='venue_type', \n",
    "                                   columns='metro_area', \n",
    "                                   values='avg_utilization_rate')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pivot_util, annot=True, fmt='.1f', cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Utilization Rate (%)'})\n",
    "plt.title('Venue Utilization Rate by Type and Metro')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Supply Metrics Analyzed\")\n",
    "print(f\"  - Highest utilization: {utilization_df['avg_utilization_rate'].max():.1f}%\")\n",
    "print(f\"  - Lowest utilization: {utilization_df['avg_utilization_rate'].min():.1f}%\")\n",
    "\n",
    "# =====================================================\n",
    "# SECTION 2: DEMAND METRICS\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n2. DEMAND METRICS\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# 2.1 Search Volume Trends\n",
    "query_demand = \"\"\"\n",
    "SELECT \n",
    "    metro_area,\n",
    "    DATE(search_date, 'start of month') as month,\n",
    "    COUNT(*) as total_searches,\n",
    "    COUNT(DISTINCT user_id) as unique_searchers,\n",
    "    AVG(JULIANDAY(event_date) - JULIANDAY(search_date)) as avg_lead_time_days\n",
    "FROM searches\n",
    "GROUP BY metro_area, DATE(search_date, 'start of month')\n",
    "\"\"\"\n",
    "\n",
    "demand_df = pd.read_sql_query(query_demand, conn)\n",
    "demand_df['month'] = pd.to_datetime(demand_df['month'])\n",
    "\n",
    "# 2.2 Conversion Funnel\n",
    "query_conversion = \"\"\"\n",
    "WITH conversion_funnel AS (\n",
    "    SELECT \n",
    "        s.metro_area,\n",
    "        COUNT(DISTINCT s.search_id) as total_searches,\n",
    "        COUNT(DISTINCT CASE WHEN s.search_resulted_in_booking = 1 THEN s.search_id END) as converted_searches,\n",
    "        COUNT(DISTINCT b.booking_id) as total_bookings\n",
    "    FROM searches s\n",
    "    LEFT JOIN bookings b ON s.search_id = b.search_id\n",
    "    GROUP BY s.metro_area\n",
    ")\n",
    "SELECT \n",
    "    metro_area,\n",
    "    total_searches,\n",
    "    converted_searches,\n",
    "    ROUND(converted_searches * 100.0 / total_searches, 2) as conversion_rate\n",
    "FROM conversion_funnel\n",
    "ORDER BY conversion_rate DESC\n",
    "\"\"\"\n",
    "\n",
    "conversion_df = pd.read_sql_query(query_conversion, conn)\n",
    "\n",
    "# Visualize conversion rates\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart of conversion rates\n",
    "ax1.bar(conversion_df['metro_area'], conversion_df['conversion_rate'])\n",
    "ax1.set_xlabel('Metro Area')\n",
    "ax1.set_ylabel('Conversion Rate (%)')\n",
    "ax1.set_title('Search-to-Booking Conversion Rate by Metro')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Funnel visualization for top metro\n",
    "top_metro = conversion_df.iloc[0]['metro_area']\n",
    "top_metro_data = conversion_df[conversion_df['metro_area'] == top_metro].iloc[0]\n",
    "funnel_data = [\n",
    "    top_metro_data['total_searches'],\n",
    "    top_metro_data['converted_searches'],\n",
    "    top_metro_data['converted_searches'] * 0.9  # Assuming 90% complete booking\n",
    "]\n",
    "funnel_labels = ['Searches', 'Conversions', 'Completed']\n",
    "\n",
    "ax2.barh(range(len(funnel_data)), funnel_data, color=['#3498db', '#2ecc71', '#27ae60'])\n",
    "ax2.set_yticks(range(len(funnel_labels)))\n",
    "ax2.set_yticklabels(funnel_labels)\n",
    "ax2.set_xlabel('Count')\n",
    "ax2.set_title(f'Conversion Funnel - {top_metro}')\n",
    "\n",
    "for i, v in enumerate(funnel_data):\n",
    "    ax2.text(v + 10, i, f'{int(v):,}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Demand Metrics Analyzed\")\n",
    "print(f\"  - Best conversion rate: {conversion_df['conversion_rate'].max():.1f}% ({conversion_df.iloc[0]['metro_area']})\")\n",
    "print(f\"  - Worst conversion rate: {conversion_df['conversion_rate'].min():.1f}% ({conversion_df.iloc[-1]['metro_area']})\")\n",
    "\n",
    "# =====================================================\n",
    "# SECTION 3: LIQUIDITY SCORE\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n3. LIQUIDITY SCORE CALCULATION\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "query_liquidity = \"\"\"\n",
    "WITH liquidity_components AS (\n",
    "    SELECT \n",
    "        l.metro_area,\n",
    "        COUNT(DISTINCT l.venue_id) as supply_count,\n",
    "        COUNT(DISTINCT s.search_id) as demand_count,\n",
    "        COUNT(DISTINCT b.booking_id) as booking_count,\n",
    "        COUNT(DISTINCT CASE WHEN s.search_resulted_in_booking = 1 THEN s.search_id END) as converted_searches,\n",
    "        COUNT(DISTINCT l.venue_type) as supply_diversity\n",
    "    FROM listings l\n",
    "    LEFT JOIN searches s ON l.metro_area = s.metro_area\n",
    "    LEFT JOIN bookings b ON b.venue_id = l.venue_id AND b.status = 'completed'\n",
    "    GROUP BY l.metro_area\n",
    "),\n",
    "liquidity_scores AS (\n",
    "    SELECT \n",
    "        metro_area,\n",
    "        supply_count,\n",
    "        demand_count,\n",
    "        booking_count,\n",
    "        ROUND(converted_searches * 100.0 / NULLIF(demand_count, 0), 2) as conversion_score,\n",
    "        ROUND(MIN(booking_count * 10.0 / NULLIF(supply_count, 0), 100), 2) as utilization_score,\n",
    "        ROUND(100 - ABS(demand_count * 1.0 / NULLIF(supply_count, 0) - 10) * 5, 2) as balance_score,\n",
    "        ROUND(supply_diversity * 20, 2) as diversity_score\n",
    "    FROM liquidity_components\n",
    ")\n",
    "SELECT \n",
    "    metro_area,\n",
    "    supply_count,\n",
    "    demand_count,\n",
    "    booking_count,\n",
    "    conversion_score,\n",
    "    utilization_score,\n",
    "    balance_score,\n",
    "    diversity_score,\n",
    "    ROUND(\n",
    "        conversion_score * 0.35 +\n",
    "        utilization_score * 0.25 +\n",
    "        balance_score * 0.25 +\n",
    "        diversity_score * 0.15,\n",
    "    2) as liquidity_score,\n",
    "    CASE \n",
    "        WHEN (conversion_score * 0.35 + utilization_score * 0.25 + balance_score * 0.25 + diversity_score * 0.15) >= 70 THEN 'Healthy'\n",
    "        WHEN (conversion_score * 0.35 + utilization_score * 0.25 + balance_score * 0.25 + diversity_score * 0.15) >= 50 THEN 'Moderate'\n",
    "        ELSE 'Needs Attention'\n",
    "    END as market_health\n",
    "FROM liquidity_scores\n",
    "ORDER BY liquidity_score DESC\n",
    "\"\"\"\n",
    "\n",
    "liquidity_df = pd.read_sql_query(query_liquidity, conn)\n",
    "\n",
    "# Visualize liquidity scores\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Overall liquidity scores\n",
    "colors = ['green' if h == 'Healthy' else 'orange' if h == 'Moderate' else 'red' \n",
    "          for h in liquidity_df['market_health']]\n",
    "ax1.barh(liquidity_df['metro_area'], liquidity_df['liquidity_score'], color=colors)\n",
    "ax1.set_xlabel('Liquidity Score')\n",
    "ax1.set_ylabel('Metro Area')\n",
    "ax1.set_title('Overall Liquidity Score by Metro')\n",
    "ax1.set_xlim(0, 100)\n",
    "\n",
    "# Component breakdown for all metros\n",
    "components = ['conversion_score', 'utilization_score', 'balance_score', 'diversity_score']\n",
    "x = range(len(liquidity_df))\n",
    "width = 0.2\n",
    "\n",
    "for i, component in enumerate(components):\n",
    "    offset = width * (i - 1.5)\n",
    "    ax2.bar([j + offset for j in x], liquidity_df[component], \n",
    "            width, label=component.replace('_', ' ').title())\n",
    "\n",
    "ax2.set_xlabel('Metro Area')\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.set_title('Liquidity Score Components Breakdown')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(liquidity_df['metro_area'], rotation=45)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print liquidity summary\n",
    "print(\"\\n✓ Liquidity Scores Calculated\")\n",
    "print(\"\\nLiquidity Rankings:\")\n",
    "for idx, row in liquidity_df.iterrows():\n",
    "    print(f\"  {idx+1}. {row['metro_area']}: {row['liquidity_score']:.1f} ({row['market_health']})\")\n",
    "\n",
    "# =====================================================\n",
    "# SECTION 4: ACTIONABLE INSIGHTS\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n4. ACTIONABLE INSIGHTS\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# 4.1 Priority Matrix\n",
    "query_priority = \"\"\"\n",
    "WITH metro_summary AS (\n",
    "    SELECT \n",
    "        l.metro_area,\n",
    "        COUNT(DISTINCT l.venue_id) as total_venues,\n",
    "        COUNT(DISTINCT s.search_id) as total_searches,\n",
    "        COUNT(DISTINCT b.booking_id) as total_bookings,\n",
    "        COUNT(DISTINCT CASE WHEN s.search_resulted_in_booking = 0 THEN s.search_id END) as unfulfilled_searches,\n",
    "        ROUND(AVG(b.total_amount), 2) as avg_booking_value\n",
    "    FROM listings l\n",
    "    LEFT JOIN searches s ON l.metro_area = s.metro_area\n",
    "    LEFT JOIN bookings b ON b.venue_id = l.venue_id\n",
    "    GROUP BY l.metro_area\n",
    ")\n",
    "SELECT \n",
    "    metro_area,\n",
    "    total_venues,\n",
    "    total_searches,\n",
    "    total_bookings,\n",
    "    unfulfilled_searches,\n",
    "    ROUND(total_bookings * 100.0 / NULLIF(total_searches, 0), 2) as conversion_rate,\n",
    "    ROUND(unfulfilled_searches * avg_booking_value, 2) as potential_revenue_loss,\n",
    "    CASE \n",
    "        WHEN total_venues < 50 AND total_searches > 500 THEN 'URGENT: Add Supply'\n",
    "        WHEN total_venues > 100 AND total_bookings < 100 THEN 'URGENT: Generate Demand'\n",
    "        WHEN total_bookings * 100.0 / NULLIF(total_searches, 0) < 30 THEN 'MONITOR: Poor Conversion'\n",
    "        ELSE 'STABLE: Maintain'\n",
    "    END as action_required\n",
    "FROM metro_summary\n",
    "ORDER BY potential_revenue_loss DESC\n",
    "\"\"\"\n",
    "\n",
    "priority_df = pd.read_sql_query(query_priority, conn)\n",
    "\n",
    "# 4.2 Unfulfilled Demand Analysis\n",
    "query_unfulfilled = \"\"\"\n",
    "WITH unfulfilled_searches AS (\n",
    "    SELECT \n",
    "        s.metro_area,\n",
    "        s.venue_type,\n",
    "        s.capacity_needed,\n",
    "        s.max_price,\n",
    "        s.search_resulted_in_booking,\n",
    "        CASE \n",
    "            WHEN EXISTS (\n",
    "                SELECT 1 FROM listings l \n",
    "                WHERE l.metro_area = s.metro_area \n",
    "                AND l.venue_type = s.venue_type \n",
    "                AND l.capacity >= s.capacity_needed * 0.8\n",
    "                AND l.price_per_hour <= s.max_price\n",
    "                AND l.is_active = 1\n",
    "            ) THEN 1 ELSE 0 \n",
    "        END as matching_supply_exists\n",
    "    FROM searches s\n",
    "    WHERE s.search_resulted_in_booking = 0\n",
    ")\n",
    "SELECT \n",
    "    metro_area,\n",
    "    COUNT(*) as unfulfilled_searches,\n",
    "    COUNT(CASE WHEN matching_supply_exists = 0 THEN 1 END) as no_matching_supply,\n",
    "    COUNT(CASE WHEN matching_supply_exists = 1 THEN 1 END) as had_supply_but_no_booking,\n",
    "    ROUND(COUNT(CASE WHEN matching_supply_exists = 0 THEN 1 END) * 100.0 / COUNT(*), 2) as pct_true_supply_gap\n",
    "FROM unfulfilled_searches\n",
    "GROUP BY metro_area\n",
    "ORDER BY unfulfilled_searches DESC\n",
    "\"\"\"\n",
    "\n",
    "unfulfilled_df = pd.read_sql_query(query_unfulfilled, conn)\n",
    "\n",
    "# Visualize insights\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Priority matrix scatter plot\n",
    "ax1.scatter(priority_df['total_venues'], priority_df['total_searches'], \n",
    "           s=priority_df['potential_revenue_loss']/100, alpha=0.6)\n",
    "for idx, row in priority_df.iterrows():\n",
    "    ax1.annotate(row['metro_area'], (row['total_venues'], row['total_searches']))\n",
    "ax1.set_xlabel('Total Venues (Supply)')\n",
    "ax1.set_ylabel('Total Searches (Demand)')\n",
    "ax1.set_title('Supply vs Demand Matrix (bubble size = revenue opportunity)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Action required breakdown\n",
    "action_counts = priority_df['action_required'].value_counts()\n",
    "colors_action = {'URGENT: Add Supply': 'red', 'URGENT: Generate Demand': 'orange', \n",
    "                 'MONITOR: Poor Conversion': 'yellow', 'STABLE: Maintain': 'green'}\n",
    "ax2.pie(action_counts.values, labels=action_counts.index, autopct='%1.0f%%',\n",
    "        colors=[colors_action.get(x, 'gray') for x in action_counts.index])\n",
    "ax2.set_title('Metro Action Distribution')\n",
    "\n",
    "# Unfulfilled demand breakdown\n",
    "ax3.bar(unfulfilled_df['metro_area'], unfulfilled_df['no_matching_supply'], \n",
    "        label='No Supply', color='red', alpha=0.7)\n",
    "ax3.bar(unfulfilled_df['metro_area'], unfulfilled_df['had_supply_but_no_booking'], \n",
    "        bottom=unfulfilled_df['no_matching_supply'],\n",
    "        label='Had Supply', color='orange', alpha=0.7)\n",
    "ax3.set_xlabel('Metro Area')\n",
    "ax3.set_ylabel('Unfulfilled Searches')\n",
    "ax3.set_title('Unfulfilled Demand Breakdown')\n",
    "ax3.legend()\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Revenue opportunity\n",
    "ax4.barh(priority_df['metro_area'], priority_df['potential_revenue_loss'])\n",
    "ax4.set_xlabel('Potential Revenue Loss ($)')\n",
    "ax4.set_ylabel('Metro Area')\n",
    "ax4.set_title('Revenue Opportunity from Unfulfilled Demand')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Actionable Insights Generated\")\n",
    "print(\"\\nPriority Actions by Metro:\")\n",
    "for idx, row in priority_df.iterrows():\n",
    "    print(f\"\\n{row['metro_area']}:\")\n",
    "    print(f\"  Action: {row['action_required']}\")\n",
    "    print(f\"  Potential Revenue Loss: ${row['potential_revenue_loss']:,.2f}\")\n",
    "    print(f\"  Current Conversion: {row['conversion_rate']:.1f}%\")\n",
    "\n",
    "# =====================================================\n",
    "# SECTION 5: TIME SERIES ANALYSIS\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n5. TIME SERIES TRENDS\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "query_timeseries = \"\"\"\n",
    "WITH monthly_liquidity AS (\n",
    "    SELECT \n",
    "        DATE(s.search_date, 'start of month') as month,\n",
    "        s.metro_area,\n",
    "        COUNT(DISTINCT s.search_id) as searches,\n",
    "        COUNT(DISTINCT CASE WHEN s.search_resulted_in_booking = 1 THEN s.search_id END) as conversions\n",
    "    FROM searches s\n",
    "    GROUP BY DATE(s.search_date, 'start of month'), s.metro_area\n",
    ")\n",
    "SELECT \n",
    "    month,\n",
    "    metro_area,\n",
    "    searches,\n",
    "    conversions,\n",
    "    ROUND(conversions * 100.0 / NULLIF(searches, 0), 2) as conversion_rate\n",
    "FROM monthly_liquidity\n",
    "ORDER BY metro_area, month\n",
    "\"\"\"\n",
    "\n",
    "timeseries_df = pd.read_sql_query(query_timeseries, conn)\n",
    "timeseries_df['month'] = pd.to_datetime(timeseries_df['month'])\n",
    "\n",
    "# Plot conversion rate trends\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for metro in timeseries_df['metro_area'].unique():\n",
    "    metro_data = timeseries_df[timeseries_df['metro_area'] == metro]\n",
    "    ax.plot(metro_data['month'], metro_data['conversion_rate'], \n",
    "            marker='o', label=metro, linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Conversion Rate (%)')\n",
    "ax.set_title('Conversion Rate Trends by Metro')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Time Series Analysis Complete\")\n",
    "\n",
    "# =====================================================\n",
    "# SUMMARY REPORT\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LIQUIDITY ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n📊 KEY FINDINGS:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Find best and worst performing metros\n",
    "best_metro = liquidity_df.iloc[0]\n",
    "worst_metro = liquidity_df.iloc[-1]\n",
    "\n",
    "print(f\"\\n✅ BEST PERFORMING METRO: {best_metro['metro_area']}\")\n",
    "print(f\"   - Liquidity Score: {best_metro['liquidity_score']:.1f}\")\n",
    "print(f\"   - Market Health: {best_metro['market_health']}\")\n",
    "print(f\"   - Supply/Demand: {best_metro['supply_count']} venues / {best_metro['demand_count']} searches\")\n",
    "\n",
    "print(f\"\\n⚠️  NEEDS ATTENTION: {worst_metro['metro_area']}\")\n",
    "print(f\"   - Liquidity Score: {worst_metro['liquidity_score']:.1f}\")\n",
    "print(f\"   - Market Health: {worst_metro['market_health']}\")\n",
    "print(f\"   - Supply/Demand: {worst_metro['supply_count']} venues / {worst_metro['demand_count']} searches\")\n",
    "\n",
    "# Calculate total opportunity\n",
    "total_revenue_opportunity = priority_df['potential_revenue_loss'].sum()\n",
    "print(f\"\\n💰 TOTAL REVENUE OPPORTUNITY: ${total_revenue_opportunity:,.2f}\")\n",
    "\n",
    "# Identify supply gaps\n",
    "supply_gap_metros = unfulfilled_df[unfulfilled_df['pct_true_supply_gap'] > 30]\n",
    "if len(supply_gap_metros) > 0:\n",
    "    print(f\"\\n🏢 METROS WITH SUPPLY GAPS (>30% unfulfilled due to no supply):\")\n",
    "    for idx, row in supply_gap_metros.iterrows():\n",
    "        print(f\"   - {row['metro_area']}: {row['pct_true_supply_gap']:.1f}% true supply gap\")\n",
    "\n",
    "print(\"\\n📈 RECOMMENDATIONS:\")\n",
    "print(\"-\"*40)\n",
    "for idx, row in priority_df.iterrows():\n",
    "    if 'URGENT' in row['action_required']:\n",
    "        print(f\"\\n{row['metro_area']}: {row['action_required']}\")\n",
    "        if 'Add Supply' in row['action_required']:\n",
    "            print(f\"   → Launch host acquisition campaign\")\n",
    "            print(f\"   → Target: Add 20-30 new venues\")\n",
    "            print(f\"   → Focus on high-demand venue types\")\n",
    "        elif 'Generate Demand' in row['action_required']:\n",
    "            print(f\"   → Increase marketing spend by 30%\")\n",
    "            print(f\"   → Launch promotional pricing\")\n",
    "            print(f\"   → Partner with local event planners\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Analysis complete! Results saved for dashboard creation.\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save key dataframes for later use\n",
    "liquidity_df.to_csv('../data/liquidity_scores.csv', index=False)\n",
    "priority_df.to_csv('../data/priority_matrix.csv', index=False)\n",
    "conversion_df.to_csv('../data/conversion_rates.csv', index=False)\n",
    "print(\"\\n✅ Data exported to CSV files for Tableau dashboard\")\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
